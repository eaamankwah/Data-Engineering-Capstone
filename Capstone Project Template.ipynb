{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of cities, demographics and temperature on US Immigration\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project provides an opportunity to model US immigration data and to answer fundamental questions about immigration inflows in to the US. Questions such which cities do immigrants frequently target, what is the mean age of each immigrant, what visa types do immigrants possess before entering into us and what is the average temperature per month over each immigration city. \n",
    "\n",
    "Out of the four datasets provided, this project harnessed the I94 immigration data set obtained from  US National Tourism and Trade Office immigration data, US demographic dataset obtained from OpenSoft and . city temperature dataset obtained from Kaggle.\n",
    "\n",
    "The database was designed using the Star schema with four dimension tables (immigrants, city, time and monthly city temperatures ) and one fact table (immigration)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = \"/opt/conda/bin:/opt/spark-2.4.3-bin-hadoop2.7/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/lib/jvm/java-8-openjdk-amd64/bin\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/opt/spark-2.4.3-bin-hadoop2.7\"\n",
    "os.environ[\"HADOOP_HOME\"] = \"/opt/spark-2.4.3-bin-hadoop2.7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "#df_immig_i94 = spark.read.load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "df_immig_i94 = spark.read.load('./sas_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "#from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count, col, udf, year, month, avg, round, dayofweek, weekofyear, isnull\n",
    "from pyspark.sql.types import StringType, IntegerType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Scope the Project and Gather Data\n",
    "\n",
    "### Scope \n",
    "The objective of the project is to extract data from three sources and stage them. The extracted data would be transformed and aggregated into four dimension tables and one fact table so that analytics on US immigration can be performed based on city demographics and city average temperatures.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "\n",
    "**U.S. City Demographic Data**: comes from OpenSoft [demographic data](https://public.opendatasoft.com) and includes data by city, state, age, population, veteran status and race.\n",
    "\n",
    "**I94 Immigration Data**: comes from the US National Tourism and Trade Office [immigration data](https://travel.trade.gov/research/reports/i94/historical/2016.html)\n",
    "and includes details on incoming immigrants and their ports of entry.\n",
    "\n",
    "**Airport Code Table**: comes from datahub.io [airport code](https://datahub.io/core/airport-codes#data) and includes airport codes and corresponding cities.\n",
    "\n",
    "**World Temperature Data**: comes from kaggle [world temperature data](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data) and\n",
    "includes data on temperature changes in the U.S. since 1850."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read demographics data\n",
    "demog_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\", \";\").load(\"us-cities-demographics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in temperature data\n",
    "temp_df = spark.read.format(\"csv\").option(\"header\", \"true\").load('../../data2/GlobalLandTemperaturesByCity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>QF</td>\n",
       "      <td>9.495387e+10</td>\n",
       "      <td>00011</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>20591.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>VA</td>\n",
       "      <td>9.495562e+10</td>\n",
       "      <td>00007</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5748519.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495641e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5748520.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495645e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5748521.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495639e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "0  5748517.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "1  5748518.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "2  5748519.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "3  5748520.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "4  5748521.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "\n",
       "  i94addr  depdate   ...     entdepu  matflag  biryear   dtaddto gender  \\\n",
       "0      CA  20582.0   ...        None        M   1976.0  10292016      F   \n",
       "1      NV  20591.0   ...        None        M   1984.0  10292016      F   \n",
       "2      WA  20582.0   ...        None        M   1987.0  10292016      M   \n",
       "3      WA  20588.0   ...        None        M   1987.0  10292016      F   \n",
       "4      WA  20588.0   ...        None        M   1988.0  10292016      M   \n",
       "\n",
       "  insnum airline        admnum  fltno visatype  \n",
       "0   None      QF  9.495387e+10  00011       B1  \n",
       "1   None      VA  9.495562e+10  00007       B1  \n",
       "2   None      DL  9.495641e+10  00040       B1  \n",
       "3   None      DL  9.495645e+10  00040       B1  \n",
       "4   None      DL  9.495639e+10  00040       B1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immig_i94.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immig_i94.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "659\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary of valid i94 immigration valid port codes\n",
    "#immig_sas_label_descriptions_fname = \"I94_SAS_Labels_Descriptions.SAS\"\n",
    "with open(\"./I94_SAS_Labels_Descriptions.SAS\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "re_compiled = re.compile(r\"\\'(.*)\\'.*\\'(.*)\\'\")\n",
    "ports = {}\n",
    "for line in lines[302:961]:\n",
    "    match = re_compiled.search(line)\n",
    "    ports[match.group(1)] = match.group(2)\n",
    "print(len(ports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "['MD' 'MA' 'AL' 'CA' 'NJ' 'IL' 'AZ' 'MO' 'NC' 'PA' 'KS' 'FL' 'TX' 'VA' 'NV'\n",
      " 'CO' 'MI' 'CT' 'MN' 'UT' 'AR' 'TN' 'OK' 'WA' 'NY' 'GA' 'NE' 'KY' 'SC' 'LA'\n",
      " 'NM' 'IA' 'RI' 'PR' 'DC' 'WI' 'OR' 'NH' 'ND' 'DE' 'OH' 'ID' 'IN' 'AK' 'MS'\n",
      " 'HI' 'SD' 'ME' 'MT']\n"
     ]
    }
   ],
   "source": [
    "# Create list of states\n",
    "states = demog_df.toPandas()[\"State Code\"].unique()\n",
    "print(len(states))\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert SAS date to PySpark date using udf\n",
    "@udf(StringType())\n",
    "def convert_datetime(x):\n",
    "    if x:\n",
    "        return (datetime(1960, 1, 1).date() + timedelta(x)).isoformat()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate state using udf\n",
    "@udf(StringType())\n",
    "def state_validation(x):\n",
    "    if x in states:\n",
    "        return x\n",
    "    return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# immigration cleaning function\n",
    "def immig_clean(df):\n",
    "    # Remove all missing values\n",
    "    clean_immig_df = df.dropna(how=\"any\", subset=[\"i94port\", \"i94addr\", \"gender\"])\n",
    "    # Extract states\n",
    "    clean_immig_df = clean_immig_df.withColumn(\"i94addr\", state_validation(clean_immig_df.i94addr))\n",
    "    # Convert arrival_date in SAS format to PySpark format\n",
    "    clean_immig_df = clean_immig_df.withColumn(\"arrdate\", convert_datetime(clean_immig_df.arrdate))\n",
    "    # filter relevant immigration data\n",
    "    clean_immig_df = clean_immig_df.filter(clean_immig_df.i94addr != 'other')\n",
    "    return clean_immig_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>QF</td>\n",
       "      <td>9.495387e+10</td>\n",
       "      <td>00011</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>20591.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>VA</td>\n",
       "      <td>9.495562e+10</td>\n",
       "      <td>00007</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5748519.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495641e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5748520.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495645e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5748521.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495639e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon  i94cit  i94res i94port     arrdate  i94mode  \\\n",
       "0  5748517.0  2016.0     4.0   245.0   438.0     LOS  2016-04-30      1.0   \n",
       "1  5748518.0  2016.0     4.0   245.0   438.0     LOS  2016-04-30      1.0   \n",
       "2  5748519.0  2016.0     4.0   245.0   438.0     LOS  2016-04-30      1.0   \n",
       "3  5748520.0  2016.0     4.0   245.0   438.0     LOS  2016-04-30      1.0   \n",
       "4  5748521.0  2016.0     4.0   245.0   438.0     LOS  2016-04-30      1.0   \n",
       "\n",
       "  i94addr  depdate   ...     entdepu  matflag  biryear   dtaddto gender  \\\n",
       "0      CA  20582.0   ...        None        M   1976.0  10292016      F   \n",
       "1      NV  20591.0   ...        None        M   1984.0  10292016      F   \n",
       "2      WA  20582.0   ...        None        M   1987.0  10292016      M   \n",
       "3      WA  20588.0   ...        None        M   1987.0  10292016      F   \n",
       "4      WA  20588.0   ...        None        M   1988.0  10292016      M   \n",
       "\n",
       "  insnum airline        admnum  fltno visatype  \n",
       "0   None      QF  9.495387e+10  00011       B1  \n",
       "1   None      VA  9.495562e+10  00007       B1  \n",
       "2   None      DL  9.495641e+10  00040       B1  \n",
       "3   None      DL  9.495645e+10  00040       B1  \n",
       "4   None      DL  9.495639e+10  00040       B1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test function\n",
    "immig_test_df = immig_clean(df_immig_i94)\n",
    "immig_test_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+----------+----+------+---------+-----+\n",
      "|       id|      date|city_code|state_code| age|gender|visa_type|count|\n",
      "+---------+----------+---------+----------+----+------+---------+-----+\n",
      "|5925997.0|2016-04-09|      BUF|        NY|null|     U|      2.0|  1.0|\n",
      "|5928645.0|2016-04-25|      HHW|        HI|null|     U|      2.0|  1.0|\n",
      "| 158100.0|2016-04-01|      MIA|        FL| 0.0|     F|      2.0|  1.0|\n",
      "|1868564.0|2016-04-10|      NAS|        FL| 0.0|     M|      2.0|  1.0|\n",
      "|2686612.0|2016-04-15|      MIA|        FL| 0.0|     F|      2.0|  1.0|\n",
      "+---------+----------+---------+----------+----+------+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# stage immigration dataframe\n",
    "clean_immig_df = immig_test_df\n",
    "staging_immig = clean_immig_df.select(col(\"cicid\").alias(\"id\"), \n",
    "                                       col(\"arrdate\").alias(\"date\"),\n",
    "                                       col(\"i94port\").alias(\"city_code\"),\n",
    "                                       col(\"i94addr\").alias(\"state_code\"),\n",
    "                                       col(\"i94bir\").alias(\"age\"),\n",
    "                                       col(\"gender\").alias(\"gender\"),\n",
    "                                       col(\"i94visa\").alias(\"visa_type\"),\n",
    "                                       \"count\").drop_duplicates()\n",
    "\n",
    "staging_immig.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: double (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- city_code: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- visa_type: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "staging_immig.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demographics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2891"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demog_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map city name to city port abbreviation using udf\n",
    "\n",
    "@udf(StringType())\n",
    "def city_port(city):\n",
    "    for key in ports:\n",
    "        if city.lower() in ports[key].lower():\n",
    "            return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean demographics data and create new columns\n",
    "\n",
    "# Calculate demographics population percentages\n",
    "clean_demog_df = demog_df.withColumn(\"median_age\", demog_df['Median Age']) \\\n",
    "    .withColumn(\"pct_male_pop\", (demog_df['Male Population'] / demog_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"pct_female_pop\", (demog_df['Female Population'] / demog_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"pct_veterans\", (demog_df['Number of Veterans'] / demog_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"pct_foreign_born\", (demog_df['Foreign-born'] / demog_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"pct_race\", (demog_df['Count'] / demog_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"city_code\", city_port(demog_df[\"City\"])) \\\n",
    "    .dropna(how='any', subset=[\"city_code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "883"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_demog_df = clean_demog_df.select(col(\"City\").alias(\"city_name\"),\n",
    "                                        col(\"State Code\").alias(\"state_code\"), \n",
    "                         \"median_age\", \"pct_male_pop\", \"pct_female_pop\",\"pct_veterans\", \n",
    "                         \"pct_foreign_born\", \n",
    "                        col(\"Total Population\").alias(\"total_pop\"), \n",
    "                         col(\"Race\").alias(\"race\"),\n",
    "                        \"pct_race\").drop_duplicates()\n",
    "\n",
    "clean_demog_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pivot of the race column\n",
    "pivot_demog_df = clean_demog_df.groupBy(\"city_name\", \"state_code\", \"median_age\", \"pct_male_pop\",\n",
    "                                        \"pct_female_pop\",\"pct_veterans\", \"pct_foreign_born\",\n",
    "                                       \"total_pop\").pivot(\"Race\").avg(\"pct_race\")\n",
    "\n",
    "pivot_demog_df = pivot_demog_df.withColumn(\"city_code\", city_port(pivot_demog_df[\"city_name\"])) \\\n",
    "    .dropna(how='any', subset=[\"city_code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n",
      "+---------+----------+--------------+----------+------------+--------------+------------+----------------+-------------------+---------+---------+----------------------+---------+---------+\n",
      "|city_code|state_code|     city_name|median_age|pct_male_pop|pct_female_pop|pct_veterans|pct_foreign_born|pct_native_american|pct_asian|pct_black|pct_hispanic_or_latino|pct_white|total_pop|\n",
      "+---------+----------+--------------+----------+------------+--------------+------------+----------------+-------------------+---------+---------+----------------------+---------+---------+\n",
      "|      TUC|        AZ|        Tucson|      33.6|        49.8|          50.2|         7.2|             7.2|                4.6|      4.6|      6.4|                  43.5|     76.1|   531674|\n",
      "|      MCA|        TX|         Allen|      37.2|        52.3|          47.7|         3.6|             3.6|                0.2|     16.1|     13.4|                  10.8|     71.2|    98138|\n",
      "|      CRP|        TX|Corpus Christi|      35.0|        49.5|          50.5|         7.7|             7.7|                0.9|      2.8|      4.6|                  61.9|     90.3|   324082|\n",
      "|      FMY|        FL|    Fort Myers|      37.3|        49.8|          50.2|         5.8|             5.8|               null|      4.8|     23.4|                  24.1|     67.8|    74015|\n",
      "|      ORL|        FL|       Orlando|      33.1|        48.3|          51.7|         4.7|             4.7|                0.9|      4.1|     25.1|                  33.0|     66.1|   270917|\n",
      "+---------+----------+--------------+----------+------------+--------------+------------+----------------+-------------------+---------+---------+----------------------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# stage demographic data\n",
    "staging_demog_df = pivot_demog_df.select(\"city_code\", \"state_code\", \"city_name\", \"median_age\",\n",
    "                                    round(col(\"pct_male_pop\"), 1).alias(\"pct_male_pop\"),\n",
    "                                    round(col(\"pct_female_pop\"), 1).alias(\"pct_female_pop\"),\n",
    "                                    round(col(\"pct_veterans\"), 1).alias(\"pct_veterans\"),\n",
    "                                    round(col(\"pct_veterans\"), 1).alias(\"pct_foreign_born\"),\n",
    "                                    round(col(\"American Indian and Alaska Native\"), 1).alias(\"pct_native_american\"),\n",
    "                                    round(col(\"Asian\"), 1).alias(\"pct_asian\"),\n",
    "                                    round(col(\"Black or African-American\"), 1).alias(\"pct_black\"),\n",
    "                                    round(col(\"Hispanic or Latino\"), 1).alias(\"pct_hispanic_or_latino\"),\n",
    "                                    round(col(\"White\"), 1).alias(\"pct_white\"), \"total_pop\")\n",
    "print(staging_demog_df.count())\n",
    "staging_demog_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- city_code: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- city_name: string (nullable = true)\n",
      " |-- median_age: string (nullable = true)\n",
      " |-- pct_male_pop: double (nullable = true)\n",
      " |-- pct_female_pop: double (nullable = true)\n",
      " |-- pct_veterans: double (nullable = true)\n",
      " |-- pct_foreign_born: double (nullable = true)\n",
      " |-- pct_native_american: double (nullable = true)\n",
      " |-- pct_asian: double (nullable = true)\n",
      " |-- pct_black: double (nullable = true)\n",
      " |-- pct_hispanic_or_latino: double (nullable = true)\n",
      " |-- pct_white: double (nullable = true)\n",
      " |-- total_pop: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "staging_demog_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8599212"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean temperature data\n",
    "#filter U.S temperature data out of the world Temperature Data, and only use the latest year(2013)\n",
    "# remove wrong ports and map city name to port abbreviation\n",
    "\n",
    "\n",
    "ustemp_df = temp_df.filter(temp_df[\"Country\"] == \"United States\") \\\n",
    "    .withColumn(\"year\", year(temp_df['dt'])) \\\n",
    "    .withColumn(\"month\", month(temp_df[\"dt\"])) \\\n",
    "    .withColumn(\"i94port\", city_port(temp_df[\"City\"])) \\\n",
    "    .withColumn(\"AverageTemperature\", temp_df[\"AverageTemperature\"]*9/5+32) \\\n",
    "    .dropna(how='any', subset=[\"i94port\"])\n",
    "\n",
    "ustemp_df = ustemp_df.filter(year(temp_df[\"dt\"])==2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1044\n",
      "+----+-----+---------+---------------+------+------+\n",
      "|year|month|city_code|avg_temperature|   lat|  long|\n",
      "+----+-----+---------+---------------+------+------+\n",
      "|2013|    2|      OKC|           40.0|36.17N|97.46W|\n",
      "|2013|    1|      WAS|           35.3|39.38N|76.99W|\n",
      "|2013|    5|      BHX|           69.1|32.95N|87.13W|\n",
      "|2013|    8|      CLE|           69.8|40.99N|80.95W|\n",
      "|2013|    8|      HSV|           70.7|42.59N|89.45W|\n",
      "+----+-----+---------+---------------+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# stage us temperature data\n",
    "staging_ustemp_df = ustemp_df.select(col(\"year\"), col(\"month\"), \n",
    "                                     col(\"i94port\").alias(\"city_code\"),\n",
    "                                         round(col(\"AverageTemperature\"), 1).alias(\"avg_temperature\"),\n",
    "                                         col(\"Latitude\").alias(\"lat\"), \n",
    "                                     col(\"Longitude\").alias(\"long\")).drop_duplicates()\n",
    "\n",
    "print(staging_ustemp_df.count())\n",
    "staging_ustemp_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Star Schema**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "**Staging Tables**\n",
    "\n",
    "**Staging_immig**\n",
    "This table included the follow columns: id, date, city_code, state_code, age, gender, visa_type and count\n",
    "\n",
    "**Staging_ustemp**\n",
    "This table included the following columns: year, month, city_code, city_name, avg_temperature, lat and long. \n",
    "\n",
    "**Staging _demog**\n",
    "This table included the following columns: city_code, state_code, city_name, median_age, pct_male_pop, pct_female_pop, pct_veterans\n",
    "pct_foreign_born, pct_native_american, pct_asian, pct_black, pct_hispanic_or_latino, pct_white and total_pop."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "**Dimension Tables**\n",
    "\n",
    "**Immigrants**\n",
    "\n",
    "This table included the following columns: id, gender, age and visa_type.\n",
    "\n",
    "**Immigrants_city**\n",
    "\n",
    "This table included the following columns: city_code, state_code, city_name, median_age, pct_male_pop, pct_female_pop, pct_veterans\n",
    "pct_foreign_born, pct_native_american, pct_asian, pct_black, pct_hispanic_or_latino, pct_white, total_pop, lat and long.\n",
    "\n",
    "**City_monthly_temp**\n",
    "This table included the following columns: city_code, year, month and avg_temperature.\n",
    "\n",
    "**Time** \n",
    "This table included the following columns: date, dayofweek, weekofyear and month\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "**Fact Table**\n",
    "\n",
    "The main fact table (immigration) contains all the measures associated with the following columns and dimension tables: id, state_code. city_code, date and count.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapping Out Data Pipelines¶\n",
    "The steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the data pipeline to create the data model by:\n",
    "    \n",
    "1. Dropping duplicates from immigration data\n",
    "2. Creating dimension tables from cleaned data\n",
    "3. Writing each dimension table to parquet for downstream query\n",
    "4. Creating fact table\n",
    "5. Writing fact table to parquet for downstream query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dimension table for immigrant dataframe\n",
    "\n",
    "immigrants = staging_immig.select(\"id\",\n",
    "                                     \"gender\",\n",
    "                                     \"age\", \n",
    "                                     \"visa_type\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2435922"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigrants.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+----+---------+\n",
      "|       id|gender| age|visa_type|\n",
      "+---------+------+----+---------+\n",
      "| 488015.0|     M| 6.0|      2.0|\n",
      "|3885998.0|     M|11.0|      2.0|\n",
      "|3305770.0|     M|13.0|      2.0|\n",
      "|5087701.0|     F|13.0|      2.0|\n",
      "| 798492.0|     M|18.0|      2.0|\n",
      "+---------+------+----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigrants.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write immigrant dimension table to parquet\n",
    "immigrants.write.mode(\"overwrite\").partitionBy(\"gender\", \"age\").parquet(\"immigrants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dimension table for city dataframe\n",
    "\n",
    "city = staging_demog_df.join(staging_ustemp_df, \"city_code\") \\\n",
    "    .select(\"city_code\", \n",
    "            \"state_code\", \n",
    "            \"city_name\", \n",
    "            \"median_age\", \n",
    "            \"pct_male_pop\", \n",
    "            \"pct_female_pop\", \n",
    "            \"pct_veterans\",\n",
    "           \"pct_foreign_born\", \n",
    "            \"pct_native_american\",\n",
    "            \"pct_asian\", \"pct_black\",\n",
    "           \"pct_hispanic_or_latino\",\n",
    "            \"pct_white\", \n",
    "            \"total_pop\", \n",
    "            \"lat\",\n",
    "            \"long\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----------+----------+------------+--------------+------------+----------------+-------------------+---------+---------+----------------------+---------+---------+------+-------+\n",
      "|city_code|state_code|  city_name|median_age|pct_male_pop|pct_female_pop|pct_veterans|pct_foreign_born|pct_native_american|pct_asian|pct_black|pct_hispanic_or_latino|pct_white|total_pop|   lat|   long|\n",
      "+---------+----------+-----------+----------+------------+--------------+------------+----------------+-------------------+---------+---------+----------------------+---------+---------+------+-------+\n",
      "|      BRO|        TX|Brownsville|      30.6|        47.7|          52.3|         2.3|             2.3|                0.6|      0.9|      0.7|                  92.5|     95.0|   183888|26.52N| 96.72W|\n",
      "|      HSV|        WI|    Madison|      30.7|        49.2|          50.8|         3.9|             3.9|                0.9|      9.6|      8.2|                   7.9|     82.1|   248956|34.56N| 85.62W|\n",
      "|      NEW|        NJ|     Newark|      34.6|        49.0|          51.0|         2.1|             2.1|                0.8|      2.6|     51.4|                  35.6|     27.1|   281913|40.99N| 74.56W|\n",
      "|      ATL|        GA|    Atlanta|      33.8|        48.3|          51.7|         4.0|             4.0|                1.0|      5.2|     52.9|                   4.0|     42.3|   463875|34.56N| 83.68W|\n",
      "|      BFL|        CA|Bakersfield|      30.6|        48.8|          51.2|         3.3|             3.3|                2.0|      8.5|      9.2|                  48.2|     73.0|   373627|36.17N|119.34W|\n",
      "+---------+----------+-----------+----------+------------+--------------+------------+----------------+-------------------+---------+---------+----------------------+---------+---------+------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "city.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write city dimension table to parquet\n",
    "city.write.mode(\"overwrite\").partitionBy(\"state_code\").parquet(\"cities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dimension table for monthly city temperature data frame\n",
    "\n",
    "city_month_temp = staging_ustemp_df.select(\"city_code\",\n",
    "                                                \"year\",\n",
    "                                                \"month\",\n",
    "                                                \"avg_temperature\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1044"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_month_temp.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+-----+---------------+\n",
      "|city_code|year|month|avg_temperature|\n",
      "+---------+----+-----+---------------+\n",
      "|      HOU|2013|    4|           66.2|\n",
      "|      BTN|2013|    6|           83.0|\n",
      "|      RDU|2013|    1|           42.4|\n",
      "|      CIN|2013|    1|           31.5|\n",
      "|      LCB|2013|    9|           83.8|\n",
      "+---------+----+-----+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "city_month_temp.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write montly city temperature dimension table to parquet\n",
    "city_month_temp.write.mode(\"overwrite\").parquet(\"city_month_temperatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dimension table for time dataframe\n",
    "\n",
    "time = staging_immig.withColumn(\"dayofweek\", dayofweek(\"date\"))\\\n",
    "                .withColumn(\"weekofyear\", weekofyear(\"date\"))\\\n",
    "                .withColumn(\"month\", month(\"date\"))\n",
    "                        \n",
    "time = time.select(\"date\",\n",
    "                         \"dayofweek\",\n",
    "                         \"weekofyear\",\n",
    "                         \"month\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------+-----+\n",
      "|      date|dayofweek|weekofyear|month|\n",
      "+----------+---------+----------+-----+\n",
      "|2016-04-23|        7|        16|    4|\n",
      "|2016-04-22|        6|        16|    4|\n",
      "|2016-04-08|        6|        14|    4|\n",
      "|2016-04-09|        7|        14|    4|\n",
      "|2016-04-26|        3|        17|    4|\n",
      "+----------+---------+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write time dimension table to parquet\n",
    "time.write.mode(\"overwrite\").parquet(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fact table for immigration dataframe\n",
    "\n",
    "immigration = staging_immig.select(\"id\", \n",
    "                                         \"state_code\", \n",
    "                                         \"city_code\", \n",
    "                                         \"date\", \"count\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2435922"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+----------+-----+\n",
      "|       id|state_code|city_code|      date|count|\n",
      "+---------+----------+---------+----------+-----+\n",
      "|4750990.0|        HI|      HHW|2016-04-25|  1.0|\n",
      "|4308064.0|        HI|      HHW|2016-04-23|  1.0|\n",
      "|4232231.0|        FL|      ATL|2016-04-22|  1.0|\n",
      "|  56083.0|        HI|      HHW|2016-04-01|  1.0|\n",
      "|3488147.0|        NY|      NYC|2016-04-19|  1.0|\n",
      "+---------+----------+---------+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write fact table to parquet\n",
    "#immigration.write.mode(\"overwrite\").partitionBy(\"state_code\", \"city_code\").parquet(\"immigration_facts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension data quality checks passed\n",
      "dimension tables exist\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform quality checks on dimension tables\n",
    "\n",
    "def dim_table(df):\n",
    "    if df is not None:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "if dim_table(immigrants) & dim_table(city) \\\n",
    "& dim_table(city_month_temp) & dim_table(time):\n",
    "    print(\"dimension data quality checks passed\")\n",
    "    print(\"dimension tables exist\")\n",
    "    print()\n",
    "else:\n",
    "    print(\"dimension data quality check failed\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fact data quality checks passed\n",
      "fact table exist\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform quality checks on fact table\n",
    "def fact_table(df):\n",
    "    if df is not None:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "if fact_table(immigration):\n",
    "    print(\"fact data quality checks passed\")\n",
    "    print(\"fact table exist\")\n",
    "    print()\n",
    "else:\n",
    "    print(\"fact data quality check failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data quality checks passed\n",
      "non zero records check passed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform quality checks on fact table\n",
    "def non_zero_records(df):\n",
    "    return df.count() !=0\n",
    "            \n",
    "if non_zero_records(immigration):\n",
    "    print(\"data quality checks passed\")\n",
    "    print(\"non zero records check passed\")\n",
    "    print()\n",
    "else:\n",
    "    print(\"non zero records failed check failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "**Dimension Tables**\n",
    "\n",
    "immigrants\n",
    "    id: identity of immigrant\n",
    "    gender: gender of immigrant\n",
    "    age: age of immigrant\n",
    "    visa_type: visa type of each immigrant\n",
    "\n",
    "city\n",
    "    city_code: city port code\n",
    "    state_code: state code of the city\n",
    "    city_name: name of the city\n",
    "    median_age: median age of the city\n",
    "    pct_male_pop: percentage of male population in city\n",
    "    pct_female_pop: percentage of female population in city\n",
    "    pct_veterans: percentage of veteran population in city\n",
    "    pct_foreign_born: percentage of foreign born population in city\n",
    "    pct_native_american: percentage of native american population in city\n",
    "    pct_asian: percentage of asian population in city\n",
    "    pct_black: percentage of black population in city\n",
    "    pct_hispanic_or_latino: percentage of hispanic or latino population in city\n",
    "    pct_white: percentage of white population in city\n",
    "    total_pop: total population of city\n",
    "    lat: latitude of city\n",
    "    long: longitude of city\n",
    "\n",
    "city_month_temp\n",
    "    city_code: city port code\n",
    "    year: year in date\n",
    "    month: month of the year\n",
    "    avg_temperature: average temperature for given month in city\n",
    "\n",
    "time\n",
    "    date: date\n",
    "    dayofweek: day of the week\n",
    "    weekofyear: week of year\n",
    "    month: month of the year"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "**Fact Table**\n",
    "immigration_df id: id of immigrants\n",
    "     state_code: state_code of arriving city \n",
    "     city_code: city port code of arrivaving city \n",
    "     date: arrival date \n",
    "     count: count of immigrant's entering into United States"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Complete Project Write Up**\n",
    "\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rationale for the choice of tools and technologies for the project.**\n",
    "\n",
    "Spark has a Python API, PySpark capable of handling big data with speed due to it's in-memory compute technology. Spark can handle different data types such as JSON, Parquest, SAS and CSV and can also scale very well in distributed or parallel environment. Moreover, Spark integrates very well with cloud data stores such as S3 and cloud databases such as Amazon Redshift."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How often the data should be updated and why.**\n",
    "\n",
    "The data should be updated on monthly cycles because the format of the raw files are monthly. This cycle will also work for most entities such as  organizations and governments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How my approach to the problem would differ under the following scenarios:**\n",
    "\n",
    "* The data was increased by 100x.\n",
    "\n",
    "Amazon Redshift would be used since it provides analytical database which is optimized for aggregation and read-heavy workloads\n",
    "\n",
    "* The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "\n",
    "Apache Airflow or Apache Nifi could be used to create DAG pipelines or automate the process that send failures notices or perform retries.\n",
    "Daily quality checks that send failure emails to operators could be employed for consistent monitoring in order to meet users and client requiremnts.\n",
    "\n",
    "* The database needed to be accessed by 100+ people.\n",
    "\n",
    "The auto scaling capacities of redshift could be used to handle heavy loads and also attain good read performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
